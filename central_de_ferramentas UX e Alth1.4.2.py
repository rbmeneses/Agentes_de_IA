# coding: utf-8
import streamlit as st
import os
import requests
import logging
import base64
import json
from io import BytesIO
from docx import Document
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
import tempfile
import vertexai
from vertexai.vision_models import ImageGenerationModel
from vertexai.generative_models import GenerativeModel, Part
from PIL import Image as PILImage
from googleapiclient.discovery import build
from google.api_core import exceptions as google_exceptions
import yaml
from yaml.loader import SafeLoader
import streamlit_authenticator as stauth
from pathlib import Path

# --- CONFIGURA√á√ÉO GERAL E DA P√ÅGINA ---
st.set_page_config(layout="wide", page_title="Minha Plataforma de IA ")

# --- 1. DESIGN E ESTILO (UX/UI) ---
# O CSS foi mantido para preservar a identidade visual da aplica√ß√£o.
st.markdown("""
<style>
    /* Gradiente na barra lateral */
    [data-testid="stSidebar"] {
        background: linear-gradient(135deg, #3B82F6, #8B5CF6);
        color: white;
    }
    [data-testid="stSidebar"] .st-emotion-cache-1629p8f a, [data-testid="stSidebar"] .st-emotion-cache-10trblm {
        color: white;
    }
    /* Estilo dos bot√µes */
    .stButton>button {
        background-color: #8B5CF6;
        color: white;
        border: none;
        border-radius: 8px;
        padding: 10px 20px;
        transition: background-color 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #6D28D9;
    }
    /* Tipografia e Layout */
    body {
        font-family: 'Lato', 'Roboto', sans-serif;
    }
    h1, h2, h3 {
        font-weight: 300; /* Fontes mais leves e elegantes */
    }
    .stTabs, .stRadio {
        margin-top: 2em; /* Espa√ßamento generoso */
    }
</style>
""", unsafe_allow_html=True)


# --- 2. SISTEMA DE AUTENTICA√á√ÉO E GEST√ÉO DE USU√ÅRIO ---
# A estrutura de autentica√ß√£o foi mantida, pois √© robusta.
config_file = Path(__file__).parent / "config.yaml"
if not config_file.exists():
    # Cria um arquivo de configura√ß√£o padr√£o se n√£o existir
    default_config = {
        "credentials": {
            "usernames": {
                "admin": {
                    "email": "admin@example.com",
                    "name": "Administrador",
                    # Senha '12345' - Use uma ferramenta para gerar um hash bcrypt seguro para produ√ß√£o
                    "password": "$2b$12$Yg.i2h.fA94ccbCo3x.iU.W3Yv8M2d2yVpr0dFzgehJe.eAIqfC6C",
                    "api_keys": {
                        "gemini_key": "", "gcp_project_id": "", "gcp_location": "us-central1",
                        "gsearch_key": "", "gsearch_cx": ""
                    }
                }
            }
        },
        "cookie": {"expiry_days": 30, "key": "some_signature_key", "name": "ia_plataforma_cookie"},
        "preauthorized": {"emails": ["admin@example.com"]}
    }
    with open(config_file, 'w') as file:
        yaml.dump(default_config, file, default_flow_style=False)

with open(config_file) as file:
    config = yaml.load(file, Loader=SafeLoader)

authenticator = stauth.Authenticate(
    config['credentials'],
    config['cookie']['name'],
    config['cookie']['key'],
    config['cookie']['expiry_days']
)

authenticator.login()

name = st.session_state.get("name")
authentication_status = st.session_state.get("authentication_status")
username = st.session_state.get("username")

# --- L√ìGICA PRINCIPAL DA APLICA√á√ÉO ---

if not authentication_status:
    st.warning("Por favor, fa√ßa login para acessar a plataforma.")
    if authentication_status is False:
        st.error('Usu√°rio ou senha incorretos.')
    elif authentication_status is None:
        st.info('Bem-vindo! Por favor, insira seu usu√°rio e senha.')

elif authentication_status:
    # --- FUN√á√ïES UTILIT√ÅRIAS GLOBAIS E CONSTANTES ---
    # COMENT√ÅRIO DE REFATORA√á√ÉO: Centraliza√ß√£o de constantes para f√°cil manuten√ß√£o.
    GEMINI_API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta"
    GEMINI_FLASH_MODEL = "gemini-2.5-flash"
    GEMINI_PRO_MODEL = "gemini-2.5-pro" # Updated to a robust multimodal model for log analysis
    VERTEX_IMAGE_MODEL = "imagen-3.0-fast-generate-001"

    def get_api_key(key_name):
        """Busca a chave de API do perfil do usu√°rio logado de forma segura."""
        try:
            return config['credentials']['usernames'][username]['api_keys'][key_name]
        except (KeyError, TypeError):
            st.error(f"Chave de API '{key_name}' n√£o encontrada. Configure-a na p√°gina 'Perfil e Configura√ß√µes'.")
            return None

    def save_file_to_user_storage(file_stream, filename):
        """Salva um arquivo na √°rea de armazenamento persistente do usu√°rio."""
        user_dir = Path(__file__).parent / "user_files" / username
        user_dir.mkdir(parents=True, exist_ok=True)
        file_stream.seek(0)
        with open(user_dir / filename, "wb") as f:
            f.write(file_stream.getbuffer())
        st.success(f"Arquivo '{filename}' salvo com sucesso em 'Meus Arquivos'!")

    # *** CORRE√á√ÉO APLICADA AQUI ***
    # A fun√ß√£o foi movida para o escopo global para ser reutiliz√°vel.
    def get_gemini_response(prompt_text, model_name, temperature, api_key):
        """Envia um prompt para a API Gemini e retorna a resposta em texto."""
        if not api_key:
            st.error("API Key for Gemini is not configured.")
            return None
        api_endpoint = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent?key={api_key}"
        payload = {
            "contents": [{"parts": [{"text": prompt_text}]}],
            "generationConfig": {"temperature": temperature},
            "safetySettings": [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                }
            ],
        }
        try:
            response = requests.post(api_endpoint, json=payload, headers={"Content-Type": "application/json"})
            response.raise_for_status()
            result = response.json()
            if 'candidates' in result and result['candidates'][0]['content']['parts'][0]['text']:
                return result['candidates'][0]['content']['parts'][0]['text']
            else:
                st.warning("A resposta da IA n√£o continha o texto esperado.")
                return f"Resposta inesperada da API: {result}"
        except requests.exceptions.RequestException as e:
            st.error(f"Erro de requisi√ß√£o com a API Gemini: {e}")
            return f"Erro ao comunicar com a API Gemini: {e}"
        except Exception as e:
            st.error(f"Erro ao processar o prompt: {e}")
            return f"Erro ao processar o prompt: {e}"

    # --- BARRA LATERAL DE NAVEGA√á√ÉO ---
    with st.sidebar:
        st.title(f"Bem-vindo, {name}")
        st.markdown("---")

        page = st.radio("Selecione uma Ferramenta:",
                        ("P√°gina Inicial", "Gerador de Exerc√≠cios", "Otimizador de Prompt",
                         "An√°lise Visual de Imagens", "Criador de Aplicativos",
                         "F√°brica de Spritesheets 2D", "An√°lise de Logs",
                         "Espelho da Mente", "Buscador de Vagas", # Consolidated job search
                         "Meus Arquivos", "Perfil e Configura√ß√µes"))

        st.markdown("---")
        authenticator.logout("Logout", "main")

    # --- DEFINI√á√ÉO DAS P√ÅGINAS ---
    def page_inicial():
        st.title("üöÄ Minhas Ferramentas de IA")
        st.markdown("### Bem-vindo √† sua central de ferramentas de Intelig√™ncia Artificial.")
        st.success("**Novidade:** Confira os novos m√≥dulos 'An√°lise Visual de Imagens', 'Criador de Aplicativos' e 'An√°lise de Logs'!")
        st.info("Navegue pelas ferramentas usando o menu √† esquerda. Configure suas chaves de API na p√°gina 'Perfil e Configura√ß√µes' para habilitar todas as funcionalidades.")

    def page_gerador_exercicios():
        st.header("üß© Gerador de Exerc√≠cios para Estudo Adaptados")
        st.markdown("Crie exerc√≠cios personalizados. A gera√ß√£o de imagens requer a configura√ß√£o do seu Projeto Google Cloud.")

        GEMINI_API_KEY = get_api_key('gemini_key')
        GCP_PROJECT_ID = get_api_key('gcp_project_id')
        GCP_LOCATION = get_api_key('gcp_location') # Ensure GCP_LOCATION is also retrieved
        if not GEMINI_API_KEY: return
        if not GCP_PROJECT_ID: return # Added explicit check for project ID
        if not GCP_LOCATION: return # Added explicit check for location

        def ge_extract_image_prompts(content, desired_image_style=""):
            parts = content.split("[IMAGEM]")
            image_prompts = []
            for i in range(len(parts) - 1):
                before_context = parts[i][-150:]
                after_context = parts[i + 1][:150]
                image_description = f"{before_context.strip()} {after_context.strip()}"
                if desired_image_style:
                    prompt = (f"Uma imagem educacional no estilo '{desired_image_style}' para ilustrar o seguinte conceito: {image_description}. "
                              "A imagem deve ser clara, did√°tica e focada no objeto principal.")
                else:
                    prompt = f"Uma imagem educacional detalhada para o seguinte contexto: {image_description}"
                image_prompts.append(prompt)
            return image_prompts

        def ge_gerar_imagem_com_vertexai(prompt):
            try:
                vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION) # Initialize Vertex AI here
                modelo_imagem = ImageGenerationModel.from_pretrained(VERTEX_IMAGE_MODEL)
                resposta = modelo_imagem.generate_images(prompt=prompt, number_of_images=1)
                if not resposta or not resposta[0]._image_bytes:
                    st.warning(f"A IA se recusou a gerar a imagem para o prompt: '{prompt}'.")
                    return None
                return resposta[0]._image_bytes
            except Exception as e:
                st.error(f"Ocorreu um erro ao gerar a imagem via Vertex AI: {e}")
                return None

        def generate_exercises(data, api_key):
            try:
                gemini_text_model = GEMINI_FLASH_MODEL
                question_prompt = (
                    f"Por favor, gere {data['questionCount']} exerc√≠cios do tipo {data['questionType']} para o n√≠vel escolar {data['gradeLevel']}, "
                    f"dificuldade {data['difficulty']} sobre o tema '{data['theme']}'.\n"
                    f"Adapte o conte√∫do para {data['specialNeed']}.\n"
                )
                if data['include_images']:
                    question_prompt += ("\n**Instru√ß√£o Cr√≠tica para Imagens:** Voc√™ DEVE inserir o marcador `[IMAGEM]` no texto em locais relevantes para ilustrar conceitos-chave. "
                                      "√â obrigat√≥rio que o marcador `[IMAGEM]` apare√ßa no texto gerado. Exemplo: '...a mitoc√¥ndria, que √© a usina de energia da c√©lula. [IMAGEM]'\n")

                gemini_payload = {"contents": [{"parts": [{"text": question_prompt}]}]}
                url = f"{GEMINI_API_BASE_URL}/models/{gemini_text_model}:generateContent?key={api_key}"
                headers = {"Content-Type": "application/json"}
                response = requests.post(url, json=gemini_payload, headers=headers)
                response.raise_for_status()
                gemini_result = response.json()
                content = "".join(part.get('text', '') for part in gemini_result['candidates'][0]['content'].get('parts', []))

                images_data = []
                if data['include_images']:
                    image_prompts = ge_extract_image_prompts(content, data['imageStyle'])
                    if image_prompts:
                        with st.spinner(f"Gerando {len(image_prompts)} imagens..."):
                            for prompt_text in image_prompts:
                                img_bytes = ge_gerar_imagem_com_vertexai(prompt_text)
                                if img_bytes: images_data.append(img_bytes)

                file_stream = BytesIO()
                if data['outputFormat'] == 'docx':
                    doc = Document()
                    doc.add_heading('Exerc√≠cios Gerados', 0)
                    text_parts = content.split('[IMAGEM]')
                    for i, part_text in enumerate(text_parts):
                        doc.add_paragraph(part_text.strip())
                        if i < len(images_data):
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_img:
                                temp_img.write(images_data[i])
                                temp_img_path = temp_img.name
                            doc.add_picture(temp_img_path, width=doc.sections[0].page_width * 0.5)
                            os.remove(temp_img_path)
                    doc.save(file_stream)
                    file_stream.seek(0)
                    return file_stream, 'exercicios.docx', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
                else: # Handles txt and pdf
                    if data['outputFormat'] == 'pdf':
                        c = canvas.Canvas(file_stream, pagesize=A4)
                        textobject = c.beginText()
                        textobject.setTextOrigin(10, 750)
                        textobject.setFont("Helvetica", 12)
                        lines = content.split('\n')
                        for line in lines:
                            textobject.textLine(line)
                        c.drawText(textobject)
                        c.showPage()
                        c.save()
                        file_stream.seek(0)
                        return file_stream, f'exercicios.pdf', 'application/pdf'
                    else: # txt
                        file_stream.write(content.encode('utf-8'))
                        file_stream.seek(0)
                        return file_stream, f'exercicios.txt', 'text/plain'
            except Exception as e:
                raise e

        with st.form(key="exercise_form"):
            theme_input = st.text_area("üìù Tema ou Instru√ß√µes:", "Fotoss√≠ntese para o ensino fundamental", height=100)
            col1, col2, col3 = st.columns(3)
            with col1:
                question_count = st.slider("üî¢ N√∫mero de Exerc√≠cios", 1, 30, 5)
                grade_level = st.selectbox("üéì N√≠vel Escolar", ["Infantil", "Fundamental I", "Fundamental II", "M√©dio", "Superior"], index=2)
            with col2:
                difficulty = st.slider("üìä Dificuldade (0-100)", 0, 100, 40)
                question_type = st.selectbox("‚úçÔ∏è Tipo de Quest√£o", ["Discursiva", "M√∫ltipla Escolha"])
            with col3:
                include_images = st.checkbox("üñºÔ∏è Incluir imagens com Vertex AI", value=False)
                output_format = st.selectbox("üíæ Formato de Sa√≠da", ["docx", "txt", "pdf"], help="Escolha DOCX para incluir imagens; PDF e TXT n√£o incluir√£o imagens.")
                image_style = st.text_input("üé® Estilo da Imagem", "desenho vetorial simples", disabled=not include_images)

            special_need = st.selectbox("‚ôø Necessidade Espec√≠fica (Opcional)", ["Nenhuma necessidade espec√≠fica", "S√≠ndrome de Down", "TEA", "Defici√™ncia Intelectual", "TDAH"])
            submit_button = st.form_submit_button("üöÄ Gerar Exerc√≠cios")

        if submit_button:
            if not theme_input.strip():
                st.error("Por favor, insira um tema.")
            else:
                with st.spinner("Gerando exerc√≠cios..."):
                    try:
                        if include_images:
                            if not GCP_PROJECT_ID or not GCP_LOCATION:
                                st.error("Project ID ou Location do Google Cloud n√£o configurado no perfil para gerar imagens.")
                                return
                            # vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION) # Moved to ge_gerar_imagem_com_vertexai

                        payload = {'theme': theme_input, 'questionCount': question_count,
                                   'gradeLevel': grade_level, 'difficulty': difficulty, 'questionType': question_type,
                                   'specialNeed': special_need, 'include_images': include_images,
                                   'imageStyle': image_style, 'outputFormat': output_format}

                        file_stream, filename, mime = generate_exercises(payload, GEMINI_API_KEY)

                        st.success("‚úÖ Exerc√≠cios gerados com sucesso!")
                        col1, col2 = st.columns(2)
                        with col1:
                           st.download_button(label="üì• Baixar Arquivo", data=file_stream, file_name=filename, mime=mime, use_container_width=True)
                        with col2:
                            if st.button("üíæ Salvar em Meus Arquivos", use_container_width=True):
                                save_file_to_user_storage(file_stream, filename)

                    except Exception as e:
                        st.error(f"‚ùå Erro ao gerar os exerc√≠cios: {e}")

    def page_otimizador_prompt():
        st.header("‚ú® Gerador de Prompts Otimizados com Gemini")
        st.markdown("Preencha os campos abaixo para usar a IA para gerar um prompt otimizado para outra IA.")

        GEMINI_API_KEY = get_api_key('gemini_key')
        if not GEMINI_API_KEY: return

        media_type = st.selectbox("Tipo de M√≠dia:", ("Texto", "Imagem", "V√≠deo"), key="op_media")
        request_type = st.selectbox("Tipo de Requisi√ß√£o:", ("Gera√ß√£o de Conte√∫do", "Resumo", "Tradu√ß√£o", "An√°lise de Sentimento", "Idea√ß√£o", "Gera√ß√£o de C√≥digo", "Debug", "Refatora√ß√£o", "Documenta√ß√£o", "Outro"), key="op_req")
        specific_details = st.text_area("Detalhes Espec√≠ficos (tom, formato, p√∫blico):", placeholder="Ex: Tom formal, formato de lista, p√∫blico: desenvolvedores.", key="op_details")
        content = st.text_area("Requisitos do Usu√°rio (o que voc√™ deseja que a IA fa√ßa):", placeholder="Ex: Escreva um artigo sobre os benef√≠cios da IA para pequenas empresas.", height=150, key="op_content")
        example = st.text_area("Exemplo (opcional):", placeholder="Ex: 'Introdu√ß√£o: A Intelig√™ncia Artificial est√° transformando...'", key="op_example")
        if media_type in ("Imagem", "V√≠deo"):
            media_details = st.text_area("Detalhes da Imagem/V√≠deo:", placeholder="Ex: Estilo realista, plano pr√≥ximo, 4K.", key="op_media_details")
        else:
            media_details = ""

        gemini_model = st.selectbox("Modelo Gemini:", (GEMINI_FLASH_MODEL, GEMINI_PRO_MODEL), key="op_model")
        temperature = st.slider("Temperatura:", 0.0, 1.0, 0.7, 0.05, key="op_temp")

        if st.button("Gerar Prompt Otimizado", use_container_width=True):
            if not content.strip():
                st.error("O campo 'Requisitos do Usu√°rio' √© obrigat√≥rio.")
            else:
                with st.spinner("Otimizando seu prompt..."):
                    prompt_for_gemini = (f"Gere um prompt otimizado para {media_type} com base nas informa√ß√µes: "
                                         f"- Requisi√ß√£o: {request_type} - Detalhes: {specific_details} - Requisitos: {content} "
                                         f"- Exemplo: {example or 'N/A'} - Detalhes de M√≠dia: {media_details or 'N/A'}")
                    # *** CORRE√á√ÉO APLICADA AQUI ***
                    # A chamada foi atualizada para a nova fun√ß√£o global.
                    enhanced_prompt = get_gemini_response(prompt_for_gemini, gemini_model, temperature, GEMINI_API_KEY)
                    if enhanced_prompt:
                        st.subheader("Prompt Otimizado Gerado:")
                        st.code(enhanced_prompt, language='text')

    def page_analise_visual():
        st.header("üëÅÔ∏è‚Äçüó®Ô∏è An√°lise Visual para Gera√ß√£o de Conte√∫do")
        st.markdown("Envie uma imagem (diagrama, UI, esquema, etc.) e a IA ir√° gerar c√≥digo e um prompt baseado nela.")

        GEMINI_API_KEY = get_api_key('gemini_key')
        GCP_PROJECT_ID = get_api_key('gcp_project_id')
        GCP_LOCATION = get_api_key('gcp_location')
        if not GEMINI_API_KEY or not GCP_PROJECT_ID or not GCP_LOCATION: return

        def av_analisar_imagem(image_bytes, prompt_usuario):
            try:
                vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
                multimodal_model = GenerativeModel(GEMINI_PRO_MODEL) # Use Pro model for multimodal capabilities
                image_part = Part.from_data(image_bytes, mime_type="image/png")

                instrucao_ia = f"""
                Analise a imagem fornecida. Com base em seu conte√∫do visual, gere duas sa√≠das distintas e claramente separadas:

                1.  **Gera√ß√£o de C√≥digo:** Crie um trecho de c√≥digo relevante (Python, HTML, etc.) ou pseudoc√≥digo que represente a l√≥gica, estrutura ou os elementos visuais da imagem. Se for um diagrama, gere a classe correspondente. Se for um layout de UI, gere o HTML/CSS b√°sico. Adicione um coment√°rio no in√≠cio do bloco de c√≥digo indicando a linguagem.

                2.  **Gera√ß√£o de Prompt:** Crie um prompt de texto conciso e otimizado que descreva a imagem. Este prompt deve ser formatado para ser usado diretamente na ferramenta 'Otimizador de Prompt', capturando a ess√™ncia da imagem para uma futura gera√ß√£o de conte√∫do.

                Se o usu√°rio fornecer uma instru√ß√£o espec√≠fica, leve-a em considera√ß√£o: '{prompt_usuario}'
                """

                response = multimodal_model.generate_content([instrucao_ia, image_part])
                return response.text

            except google_exceptions.GoogleAPIError as e:
                st.error(f"Google API Error durante an√°lise de imagem: {e.message}")
                return None
            except Exception as e:
                st.error(f"Erro ao analisar a imagem com o modelo multimodal: {e}")
                return None

        uploaded_file = st.file_uploader("Selecione uma imagem", type=["png", "jpg", "jpeg"])
        user_prompt = st.text_input("Instru√ß√£o Espec√≠fica (Opcional):", placeholder="Ex: 'Foco no formul√°rio de login', 'Gere o c√≥digo em Python'")

        if uploaded_file is not None:
            st.image(uploaded_file, caption="Imagem Carregada.", use_column_width=True)

            if st.button("Analisar Imagem e Gerar Conte√∫do", use_container_width=True):
                with st.spinner("A IA est√° analisando a imagem..."):
                    try:
                        image_data = uploaded_file.getvalue()

                        resultado_analise = av_analisar_imagem(image_data, user_prompt)

                        if resultado_analise:
                            st.success("An√°lise conclu√≠da com sucesso!")
                            st.markdown("---")

                            partes = resultado_analise.split("Gera√ß√£o de Prompt:")
                            if len(partes) == 2:
                                st.subheader("C√≥digo Gerado a partir da Imagem:")
                                st.code(partes[0].replace("Gera√ß√£o de C√≥digo:", "").strip(), language='python') # Default to python, user can change if needed
                                st.subheader("Prompt Otimizado para Descrever a Imagem:")
                                st.code(partes[1].strip(), language='text')
                            else:
                                st.subheader("Sa√≠da da IA (formato inesperado):")
                                st.code(resultado_analise, language='text')

                    except Exception as e:
                        st.error(f"Ocorreu um erro no processo: {e}")

    def page_criador_aplicativos():
        st.header("üèóÔ∏è Criador de Aplicativos (Scaffolding)")
        st.markdown("Gere a estrutura de arquivos e o c√≥digo base para diferentes tipos de aplica√ß√µes. Agora com prompts otimizados!")

        def ca_gerar_scaffold(project_name, app_type, extra_functions=None):
            templates = {
                "Streamlit App Simples": {
                    "app.py": f"""
import streamlit as st

st.set_page_config(page_title="{project_name}")

def main():
    st.title("Bem-vindo ao {project_name}!")
    st.write("Este √© um aplicativo Streamlit simples gerado pela Plataforma IA Evolu√≠da.")

    name = st.text_input("Qual √© o seu nome?")
    if name:
        st.write(f"Ol√°, {{name}}!")
{extra_functions or ""}
if __name__ == "__main__":
    main()
                    """,
                    "requirements.txt": "streamlit"
                },
                "API Flask B√°sica": {
                    "app.py": f"""
from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/')
def index():
    return jsonify({{"message": "Bem-vindo √† API '{project_name}'!"}})

@app.route('/api/data')
def get_data():
    return jsonify({{"id": 1, "name": "Dado de Exemplo"}})
{extra_functions or ""}
if __name__ == '__main__':
    app.run(debug=True)
                    """,
                    "requirements.txt": "Flask"
                },
                "Script de Automa√ß√£o": {
                     "main.py": f"""
import os

def main():
    print("Iniciando o script de automa√ß√£o: {project_name}")
    # Exemplo: Listar arquivos no diret√≥rio atual
    files = os.listdir('.')
    print("Arquivos encontrados:")
    for f in files:
        print(f"- {{f}}")
    print("Script conclu√≠do.")
{extra_functions or ""}
if __name__ == "__main__":
    main()
                    """,
                    "README.md": f"# {project_name}\\n\\nEste √© um script de automa√ß√£o gerado pela Plataforma IA Evolu√≠da."
                }
            }
            return templates.get(app_type, {})

        st.subheader("1. Defina os Detalhes do Projeto")
        project_name_input = st.text_input("Nome do Projeto:", "MeuNovoApp")
        app_type_select = st.selectbox(
            "Selecione o Tipo de Aplicativo:",
            ("Streamlit App Simples", "API Flask B√°sica", "Script de Automa√ß√£o")
        )

        st.subheader("2. Adicione Fun√ß√µes Extras com IA")
        extra_func_description = st.text_area(
            "Descreva fun√ß√µes extras para adicionar ao aplicativo (ex: exportar dados, autentica√ß√£o, gr√°ficos):",
            placeholder="Ex: Adicionar fun√ß√£o para exportar dados em CSV."
        )

        GEMINI_API_KEY = get_api_key('gemini_key')
        gemini_model = GEMINI_FLASH_MODEL
        temperature = 0.7

        extra_functions_code = ""
        if extra_func_description.strip():
            if not GEMINI_API_KEY:
                st.warning("Chave Gemini API n√£o configurada. Fun√ß√µes extras via IA n√£o ser√£o geradas.")
            else:
                with st.spinner("Otimizando prompt e gerando fun√ß√µes extras..."):
                    prompt_for_gemini = (
                        f"Gere fun√ß√µes Python para {app_type_select} conforme a descri√ß√£o: {extra_func_description}. "
                        "O c√≥digo deve ser pronto para uso e f√°cil de integrar ao template padr√£o."
                    )
                    # *** CORRE√á√ÉO APLICADA AQUI ***
                    # A chamada foi atualizada para a nova fun√ß√£o global, resolvendo o NameError.
                    enhanced_code = get_gemini_response(prompt_for_gemini, gemini_model, temperature, GEMINI_API_KEY)
                    if enhanced_code:
                        extra_functions_code = "\n" + enhanced_code

        if st.button("Gerar Estrutura do Aplicativo", use_container_width=True):
            if not project_name_input.strip():
                st.error("Por favor, forne√ßa um nome para o projeto.")
            else:
                with st.spinner("Gerando arquivos do projeto..."):
                    scaffold_files = ca_gerar_scaffold(project_name_input, app_type_select, extra_functions=extra_functions_code)
                    if scaffold_files:
                        st.success(f"Estrutura para '{project_name_input}' gerada!")
                        st.balloons()
                        for filename, content in scaffold_files.items():
                            with st.expander(f"üìÑ Arquivo: {filename}"):
                                st.code(content, language='python' if filename.endswith('.py') else 'text')
                    else:
                        st.error("Tipo de aplicativo n√£o encontrado.")

    def page_fabrica_spritesheets():
        st.header("üëπ F√°brica de Spritesheets 2D - Gera√ß√£o por Template Avan√ßado")
        st.markdown("Utiliza um template de prompt de alta qualidade para gerar a spritesheet completa de uma s√≥ vez.")

        GCP_PROJECT_ID = get_api_key('gcp_project_id')
        GCP_LOCATION = get_api_key('gcp_location')
        if not GCP_PROJECT_ID or not GCP_LOCATION: return

        def fs_gerar_prompt_template_avancado(data, lista_frames, estilo_arte):
            style_text = ("2D pixel art spritesheet" if estilo_arte == "Pixel Art" else "2D cartoon spritesheet")
            character_text = (f"a powerful '{data['funcao']}' character, wearing a {data['cor']}. "
                              f"Specific details: {data['detalhes']}. Wielding a {data['arma']}.")
            animation_text = ", ".join(lista_frames)
            prompt_final = (f"{style_text}, of {character_text}. "
                            f"The spritesheet must include a complete set of animation frames: {animation_text}. "
                            "Present the sprites in a clear, organized grid layout with a transparent background. "
                            "The character design must be strictly consistent across all poses. "
                            "Use a side-view perspective, optimized for smooth game animation. High resolution image.")
            return prompt_final

        def fs_gerar_imagem_google(prompt):
            try:
                vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION) # Initialize Vertex AI here
                st.info(f"Enviando o prompt para a IA...")
                modelo = ImageGenerationModel.from_pretrained(VERTEX_IMAGE_MODEL)
                resposta = modelo.generate_images(prompt=prompt, number_of_images=1, aspect_ratio="16:9")
                if not resposta or not resposta[0]._image_bytes:
                    st.warning("A IA se recusou a gerar a imagem. Tente uma descri√ß√£o diferente.")
                    return None
                return resposta[0]._image_bytes
            except Exception as e:
                st.error(f"Erro ao gerar a imagem via Vertex AI: {e}")
                return None

        st.subheader("1. Defina os Detalhes do Personagem")
        estilo_arte_selecionado = st.selectbox("Estilo de Arte", ["Pixel Art", "Cartoon"], key="fs_style_select")
        col1, col2 = st.columns(2)
        with col1:
            funcao = st.text_input("Fun√ß√£o ou Classe", "Mago Arcano", key="fs_funcao")
            arma = st.text_input("Arma/Equipamento", "cajado de madeira com orbe brilhante", key="fs_arma")
        with col2:
            cor = st.text_input("Cores Dominantes", "manto azul escuro e t√∫nica roxa", key="fs_cor")
        detalhes = st.text_area("Detalhes Visuais", "anci√£o com longa barba branca e express√£o s√°bia", key="fs_detalhes", height=100)

        st.subheader("2. Selecione as Anima√ß√µes")
        frames_disponiveis = ["Idle", "Walk", "Run", "Jump (take-off and landing)", "Basic Melee Attack (staff swing)", "Magic Spell Cast (fireball)", "Hurt", "Block", "Death animation"]
        frames_selecionados = st.multiselect("Selecione os frames para a spritesheet", options=frames_disponiveis, default=["Idle", "Walk", "Run", "Magic Spell Cast (fireball)"])

        if st.button("üëπ Gerar Spritesheet", use_container_width=True):
            if not frames_selecionados:
                st.warning("Selecione pelo menos um frame de anima√ß√£o.")
            else:
                try:
                    # vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION) # Moved to fs_gerar_imagem_google
                    with st.spinner("Construindo prompt e gerando a imagem..."):
                        dados_personagem = {"funcao": funcao, "detalhes": detalhes, "arma": arma, "cor": cor}
                        prompt_completo = fs_gerar_prompt_template_avancado(dados_personagem, frames_selecionados, estilo_arte_selecionado)
                        imagem_gerada_bytes = fs_gerar_imagem_google(prompt_completo)

                        if imagem_gerada_bytes:
                            st.success("Spritesheet gerada com sucesso!")
                            st.image(imagem_gerada_bytes, caption="Resultado da gera√ß√£o com o template.", use_container_width=True)
                            st.download_button("üì• Baixar Spritesheet (PNG)", data=imagem_gerada_bytes, file_name=f"{funcao.replace(' ', '_').lower()}_spritesheet.png", mime="image/png", use_container_width=True)
                except Exception as e:
                    st.error(f"Erro ao gerar imagens com Vertex AI: {e}")

    # --- NEW PAGE: AN√ÅLISE DE LOGS ---
    def page_analise_logs():
        st.header("üìä An√°lise de Logs e Eventos com IA")
        st.markdown("Cole o conte√∫do do seu log ou fa√ßa upload de uma imagem (ex: screenshot de erro) para a IA analisar e fornecer insights.")

        GEMINI_API_KEY = get_api_key('gemini_key')
        GCP_PROJECT_ID = get_api_key('gcp_project_id')
        GCP_LOCATION = get_api_key('gcp_location')

        if not GEMINI_API_KEY or not GCP_PROJECT_ID or not GCP_LOCATION:
            st.warning("Configure suas chaves de API para Gemini, Google Cloud Project ID e Location na aba 'Perfil e Configura√ß√µes' para usar esta ferramenta.")
            return

        def al_analisar_imagem_multimodal(image_bytes, prompt_usuario):
            try:
                vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
                multimodal_model = GenerativeModel(GEMINI_PRO_MODEL)
                image_part = Part.from_data(image_bytes, mime_type="image/png") # Assuming PNG for image logs

                instrucao_ia = f"""
                Analise esta imagem que faz parte de um log ou representa um evento do sistema.
                Extraia qualquer texto vis√≠vel (OCR), identifique diagramas, gr√°ficos ou estruturas visuais.
                Descreva o conte√∫do visual de forma concisa e relevante para a an√°lise de logs.
                Se for um diagrama de fluxo, descreva o fluxo. Se for um erro, transcreva-o.
                Sua an√°lise deve ser √∫til para complementar a compreens√£o do log textual.
                Instru√ß√£o espec√≠fica do usu√°rio: '{prompt_usuario}'
                """
                response = multimodal_model.generate_content([instrucao_ia, image_part])
                return response.text
            except google_exceptions.GoogleAPIError as e:
                st.error(f"Erro na API do Google ao analisar a imagem: {e.message}")
                return f"Erro na an√°lise visual da imagem: {e.message}"
            except Exception as e:
                st.error(f"Ocorreu um erro inesperado ao analisar a imagem: {e}")
                return f"Erro na an√°lise visual da imagem: {e}"

        with st.form(key="log_analysis_form"):
            st.subheader("1. Forne√ßa o Conte√∫do do Log")
            log_content = st.text_area("üìú Cole o conte√∫do do log aqui:", height=250,
                                       placeholder="Ex: [2023-10-26 14:30:15] ERROR: Falha na conex√£o com o banco de dados. Erro: Timeout, host=db.example.com")

            uploaded_image_log = st.file_uploader("üñºÔ∏è Ou fa√ßa upload de uma imagem de log/evento (opcional):", type=["png", "jpg", "jpeg"])
            image_analysis_instruction = st.text_input("Instru√ß√£o para an√°lise da imagem (opcional):",
                                                        placeholder="Ex: 'Foque no diagrama de rede', 'Transcreva o erro na tela'")

            st.subheader("2. Detalhes Adicionais (Opcional)")
            col1, col2, col3 = st.columns(3)
            with col1:
                log_type = st.selectbox("Tipo de Log:", ["Geral", "Sistema", "Aplica√ß√£o", "Seguran√ßa", "Rede", "Banco de Dados", "Outro"])
            with col2:
                data_inicio = st.date_input("Data de In√≠cio:", value=None, key="log_start_date")
            with col3:
                data_fim = st.date_input("Data de Fim:", value=None, key="log_end_date")

            col4, col5 = st.columns(2)
            with col4:
                gravidade = st.selectbox("Gravidade:", ["Qualquer", "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"])
            with col5:
                data_source = st.text_input("Fonte de Dados (Sistema/Servi√ßo):", placeholder="Ex: Apache, Nginx, Kubernetes, Servidor DB")

            user_instruction = st.text_area("Instru√ß√£o espec√≠fica para a IA (como voc√™ quer a an√°lise?):", height=100,
                                            placeholder="Ex: 'Foque em anomalias de desempenho', 'Identifique tentativas de acesso n√£o autorizado'")

            submit_button = st.form_submit_button("üöÄ Analisar Log com IA")

        if submit_button:
            if not log_content and not uploaded_image_log:
                st.error("Por favor, cole o conte√∫do do log ou fa√ßa upload de uma imagem.")
            else:
                with st.spinner("Analisando log e eventos..."):
                    try:
                        image_analysis_result = ""
                        if uploaded_image_log:
                            st.info("Processando imagem de log...")
                            image_bytes = uploaded_image_log.getvalue()
                            image_analysis_result = al_analisar_imagem_multimodal(image_bytes, image_analysis_instruction)
                            if image_analysis_result:
                                st.success("An√°lise visual conclu√≠da.")
                            else:
                                st.warning("N√£o foi poss√≠vel obter uma an√°lise visual da imagem.")


                        prompt_parts = []
                        prompt_parts.append("Analise o seguinte log e eventos para identificar padr√µes, anomalias, problemas potenciais e sugerir melhorias. Forne√ßa um relat√≥rio detalhado.")
                        prompt_parts.append(f"\n--- Detalhes do Log ---")
                        prompt_parts.append(f"Tipo de Log: {log_type}")
                        if data_inicio: prompt_parts.append(f"Data de In√≠cio: {data_inicio}")
                        if data_fim: prompt_parts.append(f"Data de Fim: {data_fim}")
                        prompt_parts.append(f"Gravidade: {gravidade}")
                        if data_source: prompt_parts.append(f"Fonte de Dados: {data_source}")

                        if log_content:
                            prompt_parts.append(f"\n--- Conte√∫do Textual do Log ---\n{log_content}")

                        if image_analysis_result:
                            prompt_parts.append(f"\n--- An√°lise Visual da Imagem ---\n{image_analysis_result}")

                        if user_instruction:
                            prompt_parts.append(f"\n--- Instru√ß√µes Espec√≠ficas do Usu√°rio ---\n{user_instruction}")

                        prompt_parts.append(f"\n--- Estrutura do Relat√≥rio Requerida ---")
                        prompt_parts.append("O relat√≥rio deve ser estruturado nas seguintes se√ß√µes: ")
                        prompt_parts.append("1. **Sum√°rio Executivo:** Breve resumo das descobertas mais importantes.")
                        prompt_parts.append("2. **Eventos Chave e Linha do Tempo:** Descri√ß√£o dos eventos mais cr√≠ticos ou relevantes, com marcadores de tempo se dispon√≠veis no log.")
                        prompt_parts.append("3. **Padr√µes Identificados:** Quaisquer repeti√ß√µes, tend√™ncias ou comportamentos normais/anormais encontrados.")
                        prompt_parts.append("4. **Anomalias e Problemas:** Detalhes sobre erros, exce√ß√µes, falhas ou comportamentos inesperados.")
                        prompt_parts.append("5. **Impacto Potencial:** Explica√ß√£o de como os problemas identificados podem afetar o sistema ou os usu√°rios.")
                        prompt_parts.append("6. **Recomenda√ß√µes e Pr√≥ximos Passos:** Sugest√µes acion√°veis para resolver problemas, otimizar ou prevenir ocorr√™ncias futuras.")
                        prompt_parts.append("Use formata√ß√£o Markdown para clareza.")

                        full_prompt = "\n".join(prompt_parts)

                        analysis_result = get_gemini_response(full_prompt, GEMINI_PRO_MODEL, temperature=0.2, api_key=GEMINI_API_KEY) # Lower temperature for factual analysis

                        if analysis_result:
                            st.success("‚úÖ An√°lise de Log Conclu√≠da!")
                            st.markdown(analysis_result)
                        else:
                            st.error("‚ùå N√£o foi poss√≠vel gerar a an√°lise do log. Tente novamente ou verifique suas chaves de API.")

                    except Exception as e:
                        st.error(f"‚ùå Ocorreu um erro inesperado durante a an√°lise: {e}")


    def page_espelho_da_mente():
        st.header("‚ú® Espelho da Mente Din√¢mico")
        st.markdown("Transforme pensamentos e sentimentos complexos em arte simb√≥lica.")

        GCP_PROJECT_ID = get_api_key('gcp_project_id')
        GCP_LOCATION = get_api_key('gcp_location')
        if not GCP_PROJECT_ID or not GCP_LOCATION: return

        def em_criar_prompt_avancado_com_ia(dados_usuario):
            GEMINI_API_KEY = get_api_key('gemini_key') # Retrieve API key here as well for this function
            if not GEMINI_API_KEY:
                return None
            modelo_texto = GenerativeModel(GEMINI_FLASH_MODEL)
            prompt_base = f"""
            Sua tarefa √© atuar como um engenheiro de prompt especialista em gera√ß√£o de imagens art√≠sticas.
            Converta a descri√ß√£o do usu√°rio em um prompt em ingl√™s, detalhado e evocativo para um modelo de IA de imagem.
            O objetivo √© criar uma met√°fora visual do sentimento do usu√°rio.

            **Diretrizes:**
            1. **Estilo e Atmosfera:** O estilo principal √© '{dados_usuario['estilo']}'. Descreva a atmosfera usando luz, sombra e a paleta de cores '{dados_usuario['cores']}' para intensificar a emo√ß√£o.
            2. **Composi√ß√£o:** Cen√°rio: '{dados_usuario['cenario']}'. Ponto focal: '{dados_usuario['objeto']}', que simboliza a experi√™ncia.
            3. **Simbolismo:** Incorpore o sentimento '{dados_usuario['pensamento']}' na cena de forma sutil.
            4. **Detalhes Adicionais:** Inclua: '{dados_usuario['detalhes']}'.
            5. **Restri√ß√µes:** Evite: '{dados_usuario['evitar']}'.

            Gere o prompt final para a IA de imagem.
            """
            try:
                response = modelo_texto.generate_content([prompt_base])
                return response.text.strip()
            except google_exceptions.GoogleAPIError as e:
                st.error(f"Erro na API do Google ao criar prompt para imagem: {e.message}")
                return None
            except Exception as e:
                st.error(f"Ocorreu um erro inesperado ao criar o prompt: {e}")
                return None

        def em_gerar_imagem_google(prompt):
            try:
                vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
                modelo_imagem = ImageGenerationModel.from_pretrained(VERTEX_IMAGE_MODEL)
                resposta = modelo_imagem.generate_images(prompt=prompt, number_of_images=1, aspect_ratio="1:1")
                if not resposta or not resposta[0]._image_bytes:
                    st.warning("A IA recusou-se a gerar a imagem. Tente uma descri√ß√£o diferente.")
                    return None
                return resposta[0]._image_bytes
            except Exception as e:
                st.error(f"Erro ao gerar a imagem via Vertex AI: {e}")
                return None

        st.subheader("üé® Construa sua Vis√£o")
        pensamento_usuario = st.text_area("O que voc√™ est√° pensando ou sentindo?", "Nostalgia e esperan√ßa por um futuro incerto.", height=100, key="em_thought")
        cenario = st.text_input("Se esse sentimento fosse um lugar, qual seria?", "Uma esta√ß√£o de trem antiga e vazia ao amanhecer.", key="em_place")
        objeto = st.text_input("Qual objeto simboliza melhor este momento?", "Um √∫nico broto verde crescendo entre os trilhos.", key="em_object")
        estilo = st.selectbox("Em qual estilo de arte?", ("Surrealismo", "Impressionismo", "Arte Conceitual", "Abstrato", "Aquarela", "Fantasia Sombria", "Cyberpunk"), key="em_style")
        cores = st.text_input("Quais as cores ou paleta?", "Tons de s√©pia, cinza, com um ponto de luz dourada.", key="em_colors")
        detalhes = st.text_input("Algum detalhe adicional?", "N√©voa baixa no ch√£o, raios de sol por uma janela quebrada.", key="em_details_add")
        evitar = st.text_input("O que N√ÉO incluir na imagem?", "Pessoas, animais, rel√≥gios.", key="em_avoid")

        if st.button("‚ú® Gerar Imagem da Emo√ß√£o", use_container_width=True):
            if not all([pensamento_usuario, cenario, objeto]):
                st.warning("Por favor, preencha os campos de sentimento, lugar e objeto.")
            else:
                try:
                    # vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION) # Moved to em_gerar_imagem_google
                    with st.spinner("Etapa 1: Interpretando seus sentimentos com IA..."):
                        dados_para_prompt = {"pensamento": pensamento_usuario, "cenario": cenario, "objeto": objeto, "estilo": estilo, "cores": cores, "detalhes": detalhes, "evitar": evitar}
                        prompt_final = em_criar_prompt_avancado_com_ia(dados_para_prompt)

                    if prompt_final:
                        with st.expander("Ver o prompt t√©cnico gerado"):
                            st.write(prompt_final)

                        with st.spinner("Etapa 2: Pintando sua vis√£o..."):
                            imagem_bytes = em_gerar_imagem_google(prompt_final)

                        if imagem_bytes:
                            st.success("Sua imagem foi criada!")
                            st.image(imagem_bytes, caption="Uma reflex√£o visual do seu sentimento.", use_column_width=True)
                            st.download_button("üì• Baixar Imagem (PNG)", data=imagem_bytes, file_name="espelho_da_mente.png", mime="image/png", use_container_width=True)
                    else:
                        st.error("N√£o foi poss√≠vel gerar o prompt para a imagem.")
                except Exception as e:
                    st.error(f"Erro ao gerar a imagem: {e}")

    def page_buscador_vagas():
            st.header("üîé Buscador de Vagas de Emprego")
            st.markdown("Encontre vagas de emprego usando a Busca Customizada do Google.")

            GSEARCH_KEY = get_api_key('gsearch_key')
            GSEARCH_CX = get_api_key('gsearch_cx')
            if not GSEARCH_KEY or not GSEARCH_CX:
                st.warning("Configure suas chaves de API na aba 'Perfil e Configura√ß√µes'.")
                return

            def bv_Google_Search(query, api_key, cx):
                try:
                    service = build("customsearch", "v1", developerKey=api_key)
                    res = service.cse().list(q=query, cx=cx, num=10).execute()
                    return res.get("items", [])
                except Exception as e:
                    st.error(f"Erro ao realizar a busca: {e}")
                    return []

            query = st.text_input("Digite a profiss√£o ou √°rea que deseja buscar", placeholder="Ex: Engenheiro de Software Python")
            locais = st.text_input("Deseja restringir por local ou site espec√≠fico? (Ex: site:linkedin.com OR site:gupy.io)", placeholder="site:linkedin.com OR site:br.indeed.com")
            dork_extra = st.text_input("Termos avan√ßados (opcional, Ex: intitle:vaga OR intext:home office)", placeholder="inurl:emprego OR intitle:oportunidade")

            if st.button("Buscar Vagas", use_container_width=True):
                if query:
                    with st.spinner(f"Buscando vagas para '{query}'..."):
                        full_query_parts = [f'"{query}"'] # Exact match for the profession/area
                        if locais.strip():
                            full_query_parts.append(f"({locais})")
                        else: # Default job boards if no specific sites are provided
                            full_query_parts.append("site:linkedin.com OR site:br.indeed.com OR site:catho.com.br OR site:infojobs.com.br OR site:vagas.com.br OR site:portal.gupy.io OR site:trabalhabrasil.com.br OR site:glassdoor.com.br OR site:empregos.com.br")

                        if dork_extra.strip():
                            full_query_parts.append(dork_extra)

                        final_dork = " ".join(full_query_parts)

                        st.caption(f"Dork gerado: `{final_dork}`")
                        resultados = bv_Google_Search(final_dork, GSEARCH_KEY, GSEARCH_CX)

                        if resultados:
                            st.success(f"üîó {len(resultados)} resultado(s) encontrados!")
                            for r in resultados:
                                st.markdown(f"### [{r['title']}]({r['link']})")
                                st.caption(f"üåê Fonte: {r['displayLink']}")
                                st.write(r.get('snippet', 'Sem descri√ß√£o dispon√≠vel.'))
                                st.markdown("---")
                        else:
                            st.warning("Nenhum resultado encontrado. Experimente alterar o termo ou o filtro.")
                else:
                    st.warning("Por favor, digite um termo para a busca.")


    def page_meus_arquivos():
            st.header("üóÇÔ∏è Meus Arquivos")
            st.markdown("Aqui est√£o os arquivos que voc√™ gerou e salvou na plataforma.")

            user_dir = Path(__file__).parent / "user_files" / username
            if not user_dir.exists() or not any(user_dir.iterdir()):
                st.info("Voc√™ ainda n√£o salvou nenhum arquivo.")
                return

            files = os.listdir(user_dir)
            if not files: # Check again in case iterdir() returned something but listdir is empty (e.g., hidden files)
                 st.info("Voc√™ ainda n√£o salvou nenhum arquivo.")
                 return

            for file_name in files:
                file_path = user_dir / file_name
                with open(file_path, "rb") as f:
                    st.download_button(
                        label=f"üì• Baixar {file_name}",
                        data=f,
                        file_name=file_name,
                        key=f"download_{file_name}"
                    )
                st.markdown("---")

    def page_perfil_configuracoes():
            st.header("üë§ Perfil e Configura√ß√µes")
            st.subheader("Gerencie suas chaves de API")
            st.info("Suas chaves s√£o armazenadas de forma segura e usadas para alimentar as ferramentas da plataforma.")

            with st.form("api_keys_form"):
                st.write("**Chaves do Google / Gemini**")
                gemini_key = st.text_input("Gemini API Key", value=get_api_key('gemini_key') or "", type="password")
                gcp_project_id = st.text_input("Google Cloud Project ID", value=get_api_key('gcp_project_id') or "")
                gcp_location = st.text_input("Google Cloud Location", value=get_api_key('gcp_location') or "")

                st.write("**Chaves do Google Custom Search**")
                gsearch_key = st.text_input("Google Custom Search API Key", value=get_api_key('gsearch_key') or "", type="password")
                gsearch_cx = st.text_input("Google Custom Search CX ID", value=get_api_key('gsearch_cx') or "")

                submitted = st.form_submit_button("Salvar Configura√ß√µes")
                if submitted:
                    user_credentials = config['credentials']['usernames'][username]
                    user_credentials['api_keys']['gemini_key'] = gemini_key
                    user_credentials['api_keys']['gcp_project_id'] = gcp_project_id
                    user_credentials['api_keys']['gcp_location'] = gcp_location
                    user_credentials['api_keys']['gsearch_key'] = gsearch_key
                    user_credentials['api_keys']['gsearch_cx'] = gsearch_cx

                    with open(config_file, 'w') as file:
                        yaml.dump(config, file, default_flow_style=False)
                    st.success("Suas configura√ß√µes foram salvas com sucesso!")
                    st.rerun()

    # --- ROTEADOR DE P√ÅGINAS ---
    if page == "P√°gina Inicial":
        page_inicial()
    elif page == "Gerador de Exerc√≠cios":
        page_gerador_exercicios()
    elif page == "Otimizador de Prompt":
        page_otimizador_prompt()
    elif page == "An√°lise Visual de Imagens":
        page_analise_visual()
    elif page == "Criador de Aplicativos":
        page_criador_aplicativos()
    elif page == "F√°brica de Spritesheets 2D":
        page_fabrica_spritesheets()
    elif page == "An√°lise de Logs":
        page_analise_logs()
    elif page == "Espelho da Mente":
        page_espelho_da_mente()
    elif page == "Buscador de Vagas":
        page_buscador_vagas()
    elif page == "Meus Arquivos":
        page_meus_arquivos()
    elif page == "Perfil e Configura√ß√µes":
        page_perfil_configuracoes()
